{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIFA World Cup 2018 Predictions\n",
    "\n",
    "## Introduction\n",
    "We will predict the winning team of the 2018 FIFA World Cup by collecting, organizing and analyzing data! We will be using the data from the 2016-17 season as well as three Python libraries (**BeautifulSoup** and **Pandas**) to acomplish our task. We will be using BeautifulSoup (BS) for scraping data off the web and Pandas for data manipulation.\n",
    "\n",
    "## Methods and Processes\n",
    "**Part 1: The Methodology**\n",
    "<br>\n",
    "We will grade each player in the top Europian clubs on a merit basis - a goal will result in 3 points and an assist in 1 for the player. Then for each player, their country would inherit the player's points. Our prediction will be the country with the most points! \n",
    "<br><br>\n",
    "**Part 2: Data to be Analyzed**\n",
    "<br>\n",
    "Our data will come from the top clubs in Europe:\n",
    "1. Premier League\n",
    "    * Chelsea (winners)\n",
    "    * Tottenham Hotspur\n",
    "    * Machester City\n",
    "    * Liverpool\n",
    "    * Arsenal\n",
    "    * Manchester United\n",
    "    * Everton\n",
    "<br> <br>\n",
    "2. La Liga\n",
    "    * Real Madrid (winners)\n",
    "    * Barcelona\n",
    "    * Atletico Madrid\n",
    "<br> <br>  \n",
    "3. Bundesliga\n",
    "    * Bayern Munich (winners)\n",
    "    * Dortmund \n",
    "<br> <br>   \n",
    "4. Ligue 1\n",
    "    * Monnaco (winners)\n",
    "    * Paris Saint Germain\n",
    "<br> <br>    \n",
    "5. Serie A\n",
    "    * Juventus (winners)\n",
    "    * Roma \n",
    "    \n",
    "## Implementation\n",
    "For each team above we will use BS to scrape their starting line-up of pllayers. In our dataset of players, we will manipulate the scraped data to have the player's attributes - age, country, club, club goals and club assists. Thereafter we will assign their score and also their countries' score. Then we will analyze the results and predict a winner!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the folowing cell we will import all of our dependancies **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import dependancies \n",
    "\n",
    "from bs4 import BeautifulSoup as soup   # used for web-scrapping (traversing html)\n",
    "from urllib.request import urlopen   # web-client for grabbing webpages\n",
    "import pandas as pd   # used for manipulating data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the following cell we will scrape data off Wikipedia of players and their country, club and position **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name     Country              Club Position\n",
      "0    Keylor Navas  Costa Rica  Real Madrid C.F.       GK\n",
      "1   Dani Carvajal       Spain  Real Madrid C.F.       DF\n",
      "2   Jesús Vallejo       Spain  Real Madrid C.F.       DF\n",
      "3    Sergio Ramos       Spain  Real Madrid C.F.       DF\n",
      "4  Raphaël Varane      France  Real Madrid C.F.       DF\n"
     ]
    }
   ],
   "source": [
    "def make_dataset_of_players_info():\n",
    "\n",
    "    # urls needed for scrapping\n",
    "    pl_teams_url = [\n",
    "        'https://en.wikipedia.org/wiki/Real_Madrid_C.F.',\n",
    "        'https://en.wikipedia.org/wiki/FC_Barcelona',\n",
    "        'https://en.wikipedia.org/wiki/Atl%C3%A9tico_Madrid',\n",
    "        'https://en.wikipedia.org/wiki/AS_Monaco_FC',\n",
    "        'https://en.wikipedia.org/wiki/Paris_Saint-Germain_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Juventus_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/A.S._Roma',\n",
    "        'https://en.wikipedia.org/wiki/FC_Bayern_Munich',\n",
    "        'https://en.wikipedia.org/wiki/Borussia_Dortmund',\n",
    "        'https://en.wikipedia.org/wiki/Chelsea_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Tottenham_Hotspur_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Manchester_City_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Liverpool_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Arsenal_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Manchester_United_F.C.',\n",
    "        'https://en.wikipedia.org/wiki/Everton_F.C.'\n",
    "    ]\n",
    "\n",
    "    ''' used for storing names of entities for the players info dataset '''\n",
    "    country = []\n",
    "    position = []\n",
    "    name = []\n",
    "    club = []\n",
    "\n",
    "    for url in pl_teams_url:\n",
    "\n",
    "        ''' pull data from web-page'''\n",
    "        # establish connection and download the html file\n",
    "        u_client = urlopen(url)\n",
    "        # offloads content into a variable\n",
    "        page_html = u_client.read()\n",
    "        # close connection with client\n",
    "        u_client.close()\n",
    "\n",
    "        ''' parse the html via BS '''\n",
    "        page_soup = soup(page_html, 'html.parser')\n",
    "        players_soup = page_soup.find_all('tr', {'class': 'vcard agent'})\n",
    "        players_soup = players_soup[0: 24]\n",
    "        for player_info in players_soup:\n",
    "            country.append(player_info.find('span', {'class': 'flagicon'}).a['title'])\n",
    "            position.append(player_info.find('td', {'style': 'text-align: center;'}).a.text)\n",
    "            try:\n",
    "                name.append(player_info.find('span', {'clas': 'fn'}).a.text)\n",
    "            except AttributeError:\n",
    "                name.append(player_info.find('span', {'class': 'fn'}).text)\n",
    "            club.append(page_soup.h1.text)\n",
    "            \n",
    "            \n",
    "    ''' write data to csv file '''\n",
    "    df = pd.DataFrame({\n",
    "        'Name':name, \n",
    "        'Country': country,\n",
    "        'Club': club,\n",
    "        'Position': position})\n",
    "    df = df[['Name', 'Country', 'Club', 'Position']]\n",
    "    df.to_csv(path_or_buf='players_info.csv', index=False)\n",
    "    print(df.head())\n",
    "    \n",
    "\n",
    "''' scrape data off the web and make a dataset of players and their information '''\n",
    "make_dataset_of_players_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the following cell we will scrape data off espnfc of the top players who scored the mosts goals in each league **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name               Club Goals Scored\n",
      "0      Harry Kane  Tottenham Hotspur           29\n",
      "1   Romelu Lukaku            Everton           25\n",
      "2  Alexis Sánchez            Arsenal           24\n",
      "3   Sergio Agüero    Manchester City           20\n",
      "4     Diego Costa            Chelsea           20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_dataset_of_top_goalscorers():\n",
    "    goals_scored_in_top_leagues = [\n",
    "        'http://www.espnfc.com/english-premier-league/23/statistics/scorers?season=2016',\n",
    "        'http://www.espnfc.com/spanish-primera-division/15/statistics/scorers?season=2016',\n",
    "        'http://www.espnfc.com/german-bundesliga/10/statistics/scorers?season=2016',\n",
    "        'http://www.espnfc.com/french-ligue-1/9/statistics/scorers',\n",
    "        'http://www.espnfc.com/italian-serie-a/12/statistics/scorers?season=2016'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    names_of_players = []\n",
    "    names_of_clubs = []\n",
    "    goals_scored = []\n",
    "\n",
    "    for league in goals_scored_in_top_leagues:\n",
    "\n",
    "        ''' pull data from the weppage'''\n",
    "        # establish connection and download html file\n",
    "        u_client = urlopen(league)\n",
    "        # offload content into variable \n",
    "        page_html = u_client.read()\n",
    "        # close connection with client\n",
    "        u_client.close()\n",
    "\n",
    "        ''' parse html via BS '''\n",
    "        goals_scorers_soup = soup(page_html, 'html.parser')\n",
    "        stats = goals_scorers_soup.find('div', {'class': 'stats-top-scores'})\n",
    "        players_soup = stats.findAll('td', {'headers': 'player'})\n",
    "        clubs_soup = stats.findAll('td', {'headers': 'team'})\n",
    "        goals_soup = stats.findAll('td', {'headers': 'goals'})\n",
    "\n",
    "        ''' sort the data into columns '''\n",
    "        for player, team, goals in zip(players_soup, clubs_soup, goals_soup):\n",
    "            names_of_players.append(player.text)\n",
    "            names_of_clubs.append(team.text)\n",
    "            goals_scored.append(goals.text)\n",
    "            \n",
    "    ''' write data to csv file'''\n",
    "    df = pd.DataFrame({\n",
    "        'Name': names_of_players,\n",
    "        'Club': names_of_clubs,\n",
    "        'Goals Scored': goals_scored\n",
    "    })\n",
    "    df = df[['Name', 'Club', 'Goals Scored']]\n",
    "    df.to_csv(path_or_buf=\"top_goalscorers.csv\", index=False)\n",
    "    print(df.head())\n",
    "            \n",
    "\n",
    "''' scrape data off the web and make a dataset of top goal scorers'''\n",
    "make_dataset_of_top_goalscorers()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the following cell we will scrape data off espnfc of the top players who gave the mosts assists in each league **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name               Club Assists Given\n",
      "0    Kevin De Bruyne    Manchester City            18\n",
      "1  Christian Eriksen  Tottenham Hotspur            15\n",
      "2   Gylfi Sigurdsson       Swansea City            13\n",
      "3      Cesc Fàbregas            Chelsea            12\n",
      "4     Alexis Sánchez            Arsenal            10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_dataset_of_players_with_most_assists():\n",
    "    assists_made_in_top_leagues = [\n",
    "        'http://www.espnfc.com/english-premier-league/23/statistics/assists?season=2016',\n",
    "        'http://www.espnfc.com/spanish-primera-division/15/statistics/assists?season=2016',\n",
    "        'http://www.espnfc.com/german-bundesliga/10/statistics/assists?season=2016',\n",
    "        'http://www.espnfc.com/french-ligue-1/9/statistics/assists',\n",
    "        'http://www.espnfc.com/italian-serie-a/12/statistics/assists?season=2016'\n",
    "    ]\n",
    "    \n",
    "    ''' storing variables needed for convertring to csv file '''\n",
    "    names_of_players = []\n",
    "    names_of_clubs = []\n",
    "    assists_given = []\n",
    "\n",
    "    for league in assists_made_in_top_leagues:\n",
    "\n",
    "        ''' pull data from the weppage '''\n",
    "        # establish connection and download html file\n",
    "        u_client = urlopen(league)\n",
    "        # offload content into variable \n",
    "        page_html = u_client.read()\n",
    "        # close connection with client\n",
    "        u_client.close()\n",
    "\n",
    "        ''' parse html via BS '''\n",
    "        assists_given_soup = soup(page_html, 'html.parser')\n",
    "        stats = assists_given_soup.find('div', {'id': 'stats-top-assists'})\n",
    "        players_soup = stats.findAll('td', {'headers': 'player'})\n",
    "        clubs_soup = stats.findAll('td', {'headers': 'team'})\n",
    "        # note: assists are named as goals in the html, hence the following code\n",
    "        assists_soup = stats.findAll('td', {'headers': 'goals'})\n",
    "\n",
    "        \n",
    "        ''' sort the data into columns '''\n",
    "        for player, team, assists in zip(players_soup, clubs_soup, assists_soup):\n",
    "            names_of_players.append(player.text)\n",
    "            names_of_clubs.append(team.text)\n",
    "            assists_given.append(assists.text)\n",
    "        \n",
    "          \n",
    "    ''' write data to csv file'''\n",
    "    df = pd.DataFrame({\n",
    "        'Name': names_of_players,\n",
    "        'Club': names_of_clubs,\n",
    "        'Assists Given': assists_given\n",
    "    })\n",
    "    df = df[['Name', 'Club', 'Assists Given']]\n",
    "    df.to_csv(path_or_buf=\"top_assists.csv\", index=False)\n",
    "    print(df.head())\n",
    "    \n",
    "\n",
    "''' scrape data off the web and make a dataset of top players who gave the most assists '''\n",
    "make_dataset_of_players_with_most_assists()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the following cell we will merge all the data we have collected **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def merge_collected_data():\n",
    "    \n",
    "    ''' organize data for manipulation '''\n",
    "    # import general player info\n",
    "    players_info = pd.read_csv('players_info.csv', encoding='cp1252')\n",
    "    players_info_names = players_info['Name']\n",
    "    players_info_country = players_info['Country']\n",
    "    players_info_club = players_info['Club']\n",
    "    \n",
    "    # import the goalsscorers\n",
    "    goalscorer_info = pd.read_csv('top_goalscorers.csv', encoding='cp1252')\n",
    "    goalscorer_info_names = goalscorer_info['Name']    \n",
    "    goalscorer_info_club = goalscorer_info['Club']\n",
    "    goalscorer_info_goals = goalscorer_info['Goals Scored']\n",
    "    \n",
    "    # import the assist givers\n",
    "    assists_info = pd.read_csv('top_assists.csv', encoding='cp1252')\n",
    "    assists_info_names = assists_info['Name']\n",
    "    assists_info_club = assists_info['Club']\n",
    "    assists_info_assists = assists_info['Assists Given']\n",
    "    \n",
    "    ''' columns for our merged dataset '''\n",
    "    output_goals = []    \n",
    "    output_assists = []\n",
    "    for i in players_info_names:\n",
    "        output_goals.append(0)\n",
    "        output_assists.append(0)\n",
    "    \n",
    "    ''' goals the player has scored '''\n",
    "    for i in range(len(goalscorer_info_names)):\n",
    "        name_info = goalscorer_info_names[i]\n",
    "        for j in range(len(players_info_names)):\n",
    "            if name_info == players_info_names[j]:\n",
    "                output_goals[j] = goalscorer_info_goals[i]\n",
    "                break\n",
    "                \n",
    "    ''' assists player has made '''            \n",
    "    for i in range(len(assists_info_names)):\n",
    "        name_info = assists_info_names[i]\n",
    "        for j in range(len(players_info_names)):\n",
    "            if name_info == players_info_names[j]:\n",
    "                output_assists[j] = assists_info_assists[i]\n",
    "                break\n",
    "                \n",
    "                \n",
    "    ''' create new dataframe for merging '''\n",
    "    # make new dataframe\n",
    "    goals_assists_df = pd.DataFrame({'Goals': output_goals, 'Assists': output_assists})\n",
    "    # merge dataframe\n",
    "    players_info = players_info.join(goals_assists_df)\n",
    "    \n",
    "    ''' write new dataset to csv file'''\n",
    "    players_info.to_csv(path_or_buf='merged.csv', index=False)\n",
    "    \n",
    "\n",
    "''' merge data '''\n",
    "merge_collected_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 teams that are more likey to win the world cup are: \n",
      "1)  Spain \t (points:425)\n",
      "2)  France \t (points:405)\n",
      "3)  Argentina \t (points:358)\n",
      "4)  England \t (points:294)\n",
      "5)  Brazil \t (points:265)\n",
      "6)  Belgium \t (points:230)\n",
      "7)  Uruguay \t (points:209)\n",
      "8)  Germany \t (points:142)\n",
      "9)  Portugal \t (points:114)\n",
      "10)  Poland \t (points:113)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_the_winning_country():\n",
    "    \n",
    "    ''' import needed datasets and columns '''\n",
    "    players_info = pd.read_csv('merged.csv', encoding='cp1252')\n",
    "    player_name = players_info['Name']\n",
    "    player_country = players_info['Country']\n",
    "    player_goals = players_info['Goals']\n",
    "    player_assists = players_info['Assists']\n",
    "    \n",
    "    ''' returns a list of unique countries'''\n",
    "    def find_unique_countries(countries):\n",
    "        countries = sorted(countries)\n",
    "        last = ''\n",
    "        list_of_countries = []\n",
    "        for country in countries:\n",
    "            if last != country:\n",
    "                list_of_countries.append(country)\n",
    "                last = country\n",
    "        return list_of_countries\n",
    "\n",
    "    \n",
    "    ''' create a dictionary so we can increment chances the country has of winning '''\n",
    "    countries = find_unique_countries(player_country)\n",
    "    zeros = []\n",
    "    for i in range(len(countries)):\n",
    "        zeros.append(0)\n",
    "    dictionary_of_countries = dict(zip(countries, zeros))\n",
    "    \n",
    "    ''' assign scores to the countries based on goals and assists'''\n",
    "    for country, goals, assists in zip(player_country, player_goals, player_assists):\n",
    "        points_for_goal = goals * 3\n",
    "        points_for_assists = assists * 1\n",
    "        dictionary_of_countries[country] += points_for_goal + points_for_assists\n",
    "        \n",
    "    \n",
    "    winners = dict(zip(dictionary_of_countries.values(), dictionary_of_countries.keys()))\n",
    "    print('The top 10 teams that are more likey to win the world cup are: ')\n",
    "    for i in range(1, 11):\n",
    "        reason = '(points:' + str(max(winners)) + ')'\n",
    "        print(str(i)+') ', winners[max(winners)], '\\t', reason)\n",
    "        winners.pop(max(winners))\n",
    "    \n",
    "    \n",
    "\n",
    "''' predict the winning country '''\n",
    "predict_the_winning_country()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
